{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "555814c1",
   "metadata": {},
   "source": [
    "# Research Question: \n",
    "\n",
    "Question: Can we predict the number of people who attain their bachelor's in an OECD country? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1037dfc0",
   "metadata": {},
   "source": [
    "In this assignment, we want to predict the number of people in OECD countrys that complete their Bachelor's degree. Facors like the country's GDP, ratio of people enrolled in primary education, secondary education, and tertiary education, the population of the country, how much the government spends on higher education, how much households spend on higher education, number of public universities, number of private universities, average cost of higher education, household income, and the year are all included as variables in this model. We will train a multivariate regression to see if we can reliably predict the number of people graduating with their bachelors.\n",
    "\n",
    "Our inspiration for this project stemmed from https://icfdn.org/our-impact/education/. In this website, we found out that \"Just one extra year of schooling can increase an individual’s earnings by up to 10%, and can raise the region’s average annual gross domestic product (GDP) growth by 0.37%.\" Because of this we wanted to explore how factors of education in a country can impact a country's GDP. \n",
    "\n",
    "We decided to only evaluate countries that are part of the Organization for Economic Co-operation and Development (OECD). There are 37 countries that are part of this organization that collaborate to develop policy standards and economic growth. We chose countries that are part of the OECD to evalvuate on because they account for three-fifths of the world's GDP, three-quarters of world trade, half of the world's energy consumption, and 18 percent of the world's population. Because these 37 countries account for a huge part of a country's GDP, we decided that this group of countries would be easier to evaluate compared attaining data from all 197 countries in the world.  https://www.state.gov/the-organization-for-economic-co-operation-and-development-oecd/#:~:text=and%20Development%20(OECD)-,The%20Organization%20for%20Economic%20Cooperation%20and%20Development%20(OECD),to%20promote%20sustainable%20economic%20growth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "131fa92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import duckdb "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2562c387",
   "metadata": {},
   "source": [
    "# Data Collection/Cleaning: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dc29fb",
   "metadata": {},
   "source": [
    "## Enrollment rates in early childhood education: \n",
    "https://data.oecd.org/students/enrolment-rate-in-early-childhood-education.htm\n",
    "\n",
    "This data set shows the enrollment rates in early childhood education in OECD countries. The net enrollment rates are calculated by the number of students of a particular age group (ages 3-5) enrolled in early childhood education by the size of the population of that age group. This data set only includes enrollment rates from 2013-2020.\n",
    "\n",
    "The original data set has 8 different columns: Location, Indicator, Subject, Measure, Frequency, Time, Value, Flag Codes). The Location would specificy what country. The indicator specified what type of education that age group was enrolled in. This column would be helpful for us because when we combine all the data sets, we need to use this indicator value to differentiate what type of education they are enrolled in. The subject column listed the age group of each row (ages 3-5). The Measure column just specifies how the data was separated. Because this data set is a part of a larger Education database, the measure value just indicated how each age group was grouped by, and in this case it is age. Because the Measure is the same for all the rows, this column isn't necessary. The frequency column is similar to the Measure column and is also not necessary for this case. The Time column indicates what year each enrollment rate is from, ranges from years 2013 to 2020. The Value column is displays the net enrollment percentages for each row. And the last column, Flag Codes, is used for indicating something wrong for each row, in this case, because the whole column does not contain any values, this column is not necessary.\n",
    "\n",
    "From the original data set, I removed the Measure, Frequency, and Flag Codes columns. After removing these columns, the data set only includes the columns: Location, Indicator, Subject, Measure, Frequency, and Time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "521dfaa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'enrollment rate in early childhood education.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m enrollment_early_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menrollment rate in early childhood education.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m        SELECT Location, Indicator, Subject, Time, Value\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m        FROM enrollment_early_df\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      6\u001b[0m enrollment_early_df \u001b[38;5;241m=\u001b[39m duckdb\u001b[38;5;241m.\u001b[39msql(query)\u001b[38;5;241m.\u001b[39mdf()\n",
      "File \u001b[0;32m~/anaconda3/envs/info2950/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/info2950/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/info2950/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/envs/info2950/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/info2950/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'enrollment rate in early childhood education.csv'"
     ]
    }
   ],
   "source": [
    "enrollment_early_df = pd.read_csv('enrollment rate in early childhood education.csv')\n",
    "query = \"\"\"\n",
    "        SELECT Location, Indicator, Subject, Time, Value\n",
    "        FROM enrollment_early_df\n",
    "        \"\"\"\n",
    "enrollment_early_df = duckdb.sql(query).df()\n",
    "enrollment_early_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5faf215",
   "metadata": {},
   "source": [
    "Because, we want to figure out the enrollment rates for each year for each country, we need to combine all the age groups for each year for each country. To do this, we calculated the average enrollment rate for each country for each year. At the end, we dropped the Subject and Indicator columns because for this specific case we just need the enrollment rates, years, and country name. We also renamed all the columns to better represent the values in order to better represent the data and easier to understand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c816525",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = enrollment_early_df[enrollment_early_df['SUBJECT'].isin(['AGE_3', 'AGE_4', 'AGE_5'])]\n",
    "enrollment_early_education_df = filtered_df.groupby(['LOCATION','TIME'])['Value'].mean().reset_index()\n",
    "enrollment_early_education_df = enrollment_early_education_df.drop_duplicates()\n",
    "enrollment_early_education_df = enrollment_early_education_df.rename(columns = {\"LOCATION\": \"Country\", \n",
    "                                                                                \"TIME\": \"Year\", \n",
    "                                                                               \"Value\" : \"Early Childhood Education Enrollment Rates\"})\n",
    "enrollment_early_education_df = enrollment_early_education_df.replace({\"ENROLMENT_ECE\" : \"Early Childhood\"})\n",
    "enrollment_early_education_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed4654e",
   "metadata": {},
   "source": [
    "## Enrollment rates in secondary and teritiary education: \n",
    "\n",
    "https://data.oecd.org/students/enrolment-rate-in-secondary-and-tertiary-education.htm#indicator-chart\n",
    "\n",
    "This data set shows the enrollment rates in secondary and tertiary education in OECD countries. The net enrollment rates are calculated by dividing the number of students of a particular age enrolled in these levels of education by the size of the population at that age (ages 17-19). The data set only includes data from 2013-2020.\n",
    "\n",
    "The original data set has 8 different columns: Location, Indicator, Subject, Measure, Frequency, Time, Value, Flag Codes). The Location specifies the country. The indicator specified what type of education that age group was enrolled in. This column would be helpful for us because when we combine all the data sets, we need to use this indicator value to differentiate what type of education they are enrolled in. The subject column listed the age group of each row (ages 17-19). The Measure column just specifies how the data was separated. Because this data set is a part of a larger Education database, the measure value just indicated how each age group was grouped by, and in this case it is age. Since the Measure is the same for all the rows, this column isn't necessary. The frequency column is similar to the Measure column and is also not necessary for this case. The Time column indicates what year each enrollment rate is from, ranges from years 2013 to 2020. The Value column is displays the net enrollment percentages for each row. And the last column, Flag Codes, is used for indicating something wrong for each row, in this case, because the whole column does not contain any values, this column is not necessary.\n",
    "\n",
    "From the original data set, I removed the Measure, Frequency, and Flag Codes columns. After removing these columns, the data set only includes the columns: Location, Indicator, Subject, Measure, Frequency, and Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment_higher_df = pd.read_csv('enrollment rates in secondary and tertiary education.csv')\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT Location, Indicator, Subject, Time, Value\n",
    "        FROM enrollment_higher_df\n",
    "        \"\"\"\n",
    "enrollment_higher_df = duckdb.sql(query).df()\n",
    "enrollment_higher_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e926a7",
   "metadata": {},
   "source": [
    "Because, we want to figure out the enrollment rates for each year for each country, we need to combine all the age groups for each year for each country. To do this, we calculated the average enrollment rate for each country for each year. At the end, we dropped the Subject and Indicator columns, because in this case, we just need the enrollment rates, year, and country. We also renamed all the columns to better represent the values in order to better represent the data and easier to understand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1033dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = enrollment_higher_df[enrollment_higher_df['SUBJECT'].isin(['AGE_17', 'AGE_18', 'AGE_19'])]\n",
    "enrollment_higher_education_df = filtered_df.groupby(['LOCATION','TIME'])['Value'].mean().reset_index()\n",
    "enrollment_higher_education_df = enrollment_higher_education_df.drop_duplicates()\n",
    "enrollment_higher_education_df = enrollment_higher_education_df.rename(columns = {\"LOCATION\": \"Country\", \n",
    "                                                                                \"TIME\": \"Year\", \n",
    "                                                                               \"Value\" : \"Higher Education Enrollment Rates\"})\n",
    "enrollment_higher_education_df = enrollment_higher_education_df.replace({\"ENROLMENT\" : \"Higher\"})\n",
    "enrollment_higher_education_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4053cd1",
   "metadata": {},
   "source": [
    "The two dataframes about enrollment rates in education are combined below, so that we will be able to have a cohesive dataframe that shows enrollment rates in early, and higher education in 37 different countries, from 2013 to 2017. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aad5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM enrollment_early_education_df\n",
    "        FULL JOIN enrollment_higher_education_df\n",
    "        ON enrollment_early_education_df.Country = enrollment_higher_education_df.Country\n",
    "        AND enrollment_early_education_df.Year = enrollment_higher_education_df.Year;\n",
    "        \"\"\"\n",
    "enrollment_rates_df = duckdb.sql(query).df()\n",
    "enrollment_rates_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd1e7a",
   "metadata": {},
   "source": [
    "In the table, above there are a lot of missing values. Some countries might not have enrollment rates for either early childhood education or higher education and because of this a lot of Column values for Country, and Year are filled with Nan. To fix this, we have to make all the values in the Country and Country_2 column the same, and Year and Year_2 values the same. After doing this, we need to drop the Country_2 and Year_2 columns, because they are redundant and change all the float values in Year to be integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbab61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in Country with values from Country_2\n",
    "enrollment_rates_df['Country'] = enrollment_rates_df['Country'].fillna(enrollment_rates_df['Country_2'])\n",
    "\n",
    "# Fill missing values in Country_2 with values from Country\n",
    "enrollment_rates_df['Country_2'] = enrollment_rates_df['Country_2'].fillna(enrollment_rates_df['Country'])\n",
    "\n",
    "# Fill missing values in Year with values from Year_2\n",
    "enrollment_rates_df['Year'] = enrollment_rates_df['Year'].fillna(enrollment_rates_df['Year_2'])\n",
    "\n",
    "# Fill missing values in Year_2 with values from Year\n",
    "enrollment_rates_df['Year_2'] = enrollment_rates_df['Year_2'].fillna(enrollment_rates_df['Year'])\n",
    "\n",
    "#dropping Country_2 and Year_2 columns\n",
    "enrollment_rates_df = enrollment_rates_df.drop(columns=['Country_2', 'Year_2'])\n",
    "\n",
    "#making the values in the Year column integers\n",
    "enrollment_rates_df['Year'] = enrollment_rates_df['Year'].astype(int)\n",
    "\n",
    "enrollment_rates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a7ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment_rates_df.to_csv('enrollment_rates.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14192dad",
   "metadata": {},
   "source": [
    "## GDP:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3286fb8",
   "metadata": {},
   "source": [
    "https://data.oecd.org/gdp/gross-domestic-product-gdp.htm\n",
    "\n",
    "This data set shows the nominal Gross Domestic Product(GDP) per capita of OEPD countries in US dollars from 1960 to 2022. The Gross domestic product is the standard measure of the value added created through the production of goods and servives in a country during a certain period. While the GDP per capita can be found by diving the total GDP by its population. It also measure the inclome earned from that population, the total amount spend on a final goods and services. \n",
    "\n",
    "The original data set has 8 different columns: Location, Indicator, Subject, Measure, Frequency, Time, Value, Flag Codes). The Location specifies the country. The indicator specifies what is being measured. This column is also not necessary because there is only one value being measured in this specific data set, it is redundant. The Measure column just specifies how the data was measured, in this case it was measured in US dollars. Since the Measure is the same for all the rows, this column isn't necessary. The frequency column is similar to the Measure column and is also not necessary for this case. The Time column indicates what year each gdp value is from from, ranges from years 1960 to 2022. The Value column displays the nominal gdp value. And the last column, Flag Codes, is used for indicating something wrong for each row, in this case, because the whole column does not contain any values, this column is not necessary.\n",
    "\n",
    "From the original data set, we removed the Indicator, Subject, Measure, Frequency, and Flag Codes columns. We also renamed the \"Location\" column as \"Country\" and the \"Time\" column as \"Year\" in order to be consistent with the enrollment_rates_df. We also renamed the \"Value\" column as \"GDP in US Dollars\" in order to specify the value of it, which is needed when we combine all the data sets. \n",
    "\n",
    "We also need to limit the years to be in between the years 2013 to 2020 in order to be consistent with the previous data sets found and limit the amount of nan in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1167e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_df = pd.read_csv('gdp.csv')\n",
    "query = \"\"\"\n",
    "        SELECT \n",
    "            LOCATION AS Country,\n",
    "            TIME AS Year,\n",
    "            Value AS \"GDP per Capita\"\n",
    "        FROM gdp_df\n",
    "        WHERE TIME IN (2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020);\n",
    "        \"\"\"\n",
    "gdp_df = duckdb.sql(query).df()\n",
    "gdp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8190ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_df.to_csv('clean_gdp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6696cc",
   "metadata": {},
   "source": [
    "The two dataframes (enrollment_rates_df and gdp_df) are combined below using a Full Join, so that we will have a cohesive data frame showing enrollment rates and gdp of each country from 2013-2020. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55206183",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM enrollment_rates_df\n",
    "        FULL JOIN gdp_df\n",
    "        ON enrollment_rates_df.Country = gdp_df.Country\n",
    "        AND enrollment_rates_df.Year = gdp_df.Year;\n",
    "        \"\"\"\n",
    "\n",
    "combined_df = duckdb.sql(query).df()\n",
    "combined_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03907576",
   "metadata": {},
   "source": [
    "In the table, above there are a lot of missing values. Some countries might not have enrollment rates for either early childhood education or higher education or gdp values and because of this a lot of Column values for Country, and Year are filled with Nan. To fix this, we have to make all the values in the Country and Country_2 column the same, and Year and Year_2 values the same. After doing this, we need to drop the Country_2 and Year_2 columns, because they are redundant, change all the float values in Year to be integers, and round the GDP values to two decimals to represent US dollars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87835b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in Country with values from Country_2\n",
    "combined_df['Country'] = combined_df['Country'].fillna(combined_df['Country_2'])\n",
    "\n",
    "# Fill missing values in Country_2 with values from Country\n",
    "combined_df['Country_2'] = combined_df['Country_2'].fillna(combined_df['Country'])\n",
    "\n",
    "# Fill missing values in Year with values from Year_2\n",
    "combined_df['Year'] = combined_df['Year'].fillna(combined_df['Year_2'])\n",
    "\n",
    "# Fill missing values in Year_2 with values from Year\n",
    "combined_df['Year_2'] = combined_df['Year_2'].fillna(combined_df['Year'])\n",
    "\n",
    "#dropping Country_2 and Year_2 columns\n",
    "combined_df = combined_df.drop(columns=['Country_2', 'Year_2'])\n",
    "\n",
    "#making the values in the Year column integers\n",
    "combined_df['Year'] = combined_df['Year'].astype(int)\n",
    "\n",
    "#rounding the GDP values to 2 decimals\n",
    "combined_df['GDP per Capita'] = combined_df['GDP per Capita'].round(2)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2f094b",
   "metadata": {},
   "source": [
    "## Population:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaa87b9",
   "metadata": {},
   "source": [
    "https://data.oecd.org/pop/population.htm\n",
    "\n",
    "This data set shows the total population of OECD country in millions of people from 1950 to 2022. The total population includes the following: national armed forces stationed abroad; merchant seamen at sea; diplomatic personnel located abroad; civilian aliens resident in the country; displaced persons resident in the country. However, it excludes the following: foreign armed forces stationed in the country; foreign diplomatic personnel located in the country; civilian aliens temporarily in the country.\n",
    "\n",
    "The original data set has 8 different columns: Location, Indicator, Subject, Measure, Frequency, Time, Value, Flag Codes). The Location specifies the country. The indicator specifies what is being measured (population). This column is also not necessary because there is only one value being measured in this specific data set, it is redundant. The Measure column just specifies how the data was measured, in this case it is the population per millions of people. Since the Measure is the same for all the rows, this column isn't necessary. The frequency column is similar to the Measure column and is also not necessary for this case. The Time column indicates what year each gdp value is from from, ranges from years 1950 to 2022. The Value column displays the total population per millions of people. And the last column, Flag Codes, is used for indicating something wrong for each row, in this case, because the whole column does not contain any values, this column is not necessary.\n",
    "\n",
    "From the original data set, we removed the Indicator, Subject, Measure, Frequency, and Flag Codes columns. We also renamed the \"Location\" column as \"Country\" and the \"Time\" column as \"Year\" in order to be consistent with the enrollment_rates_df. We also renamed the \"Value\" column as \"Population\" in order to specify the value of it, which is needed when we combine all the data sets. \n",
    "\n",
    "We also need to limit Years to be in between 2013 to 2020 in order to be consistent with the previous data sets and limit the amount of missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177d7659",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = pd.read_csv('population.csv')\n",
    "population_df\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT \n",
    "            LOCATION AS Country,\n",
    "            TIME AS Year,\n",
    "            Value * 1000000 AS \"Total Population\"\n",
    "        FROM population_df\n",
    "        WHERE TIME IN (2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020);\n",
    "        \"\"\"\n",
    "population_df = duckdb.sql(query).df()\n",
    "population_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9fb2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df.to_csv('clean_population.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd01a87",
   "metadata": {},
   "source": [
    "The two dataframes (combined_df and population_df) are combined below using a Full Join, so that we will have a cohesive data frame showing enrollment rates, gdp, and total population of each country from 2013-2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2222393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM combined_df\n",
    "        FULL JOIN population_df\n",
    "        ON combined_df.Country = population_df.Country\n",
    "        AND combined_df.Year = population_df.Year;\n",
    "        \"\"\"\n",
    "\n",
    "combined_df = duckdb.sql(query).df()\n",
    "combined_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f9b471",
   "metadata": {},
   "source": [
    "In the table, above there are a lot of missing values. Some countries might not have enrollment rates for either early childhood education or higher education or gdp values and because of this a lot of Column values for Country, and Year are filled with Nan. To fix this, we have to make all the values in the Country and Country_2 column the same, and Year and Year_2 values the same. After doing this, we need to drop the Country_2 and Year_2 columns, because they are redundant and change all the float values in Year to be integers, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077b23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in Country with values from Country_2\n",
    "combined_df['Country'] = combined_df['Country'].fillna(combined_df['Country_2'])\n",
    "\n",
    "# Fill missing values in Country_2 with values from Country\n",
    "combined_df['Country_2'] = combined_df['Country_2'].fillna(combined_df['Country'])\n",
    "\n",
    "# Fill missing values in Year with values from Year_2\n",
    "combined_df['Year'] = combined_df['Year'].fillna(combined_df['Year_2'])\n",
    "\n",
    "# Fill missing values in Year_2 with values from Year\n",
    "combined_df['Year_2'] = combined_df['Year_2'].fillna(combined_df['Year'])\n",
    "\n",
    "#dropping Country_2 and Year_2 columns\n",
    "combined_df = combined_df.drop(columns=['Country_2', 'Year_2'])\n",
    "\n",
    "#making the values in the Year column integers\n",
    "combined_df['Year'] = combined_df['Year'].astype(int)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c24e54",
   "metadata": {},
   "source": [
    "## Public Spending On Education:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b9b6e9",
   "metadata": {},
   "source": [
    "https://data.oecd.org/eduresource/public-spending-on-education.htm#indicator-chart\n",
    "\n",
    "This data shows the public spending on education as a percentage fo GDP for tertiary levels of education. Public spending on education includes direct expendiute on educational institutions, as well as education-related public susidies given to households and administered by educational institutions. Public entities include ministries other than ministries of education, local and regional governments, and other public agencies. Public spending includes expenditure on schools, universities and other public and private institutions delivering or supporting educational services. \n",
    "\n",
    "The original data set has 8 different columns: Location, Indicator, Subject, Measure, Frequency, Time, Value, Flag Codes). The Location specifies the country. The indicator specifies what is being measured (public spending on education). This column is also not necessary because there is only one value being measured in this specific data set, it is redundant. The Measure column just specifies how the data was measured, in this case it is the public spending as a percentage of gdp. Since the Measure is the same for all the rows, this column isn't necessary. The frequency column is similar to the Measure column and is also not necessary for this case. The Time column indicates what year each gdp value is from from, ranges from years 2000 to 2020. The Value column displays the percentage of gdp that is used for public education. And the last column, Flag Codes, is used for indicating something wrong for each row, in this case, because the whole column does not contain any values, this column is not necessary.\n",
    "\n",
    "From the original data set, we removed the Indicator, Subject, Measure, Frequency, and Flag Codes columns. We also renamed the \"Location\" column as \"Country\" and the \"Time\" column as \"Year\" in order to be consistent with the enrollment_rates_df. We also renamed the \"Value\" column as \"Public Spending on Education\" in order to specify the value of it, which is needed when we combine all the data sets.\n",
    "\n",
    "We also need to limit Years to be in between 2013 to 2020 in order to be consistent with the previous data sets and limit the amount of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_spending_df = pd.read_csv('public_spending_on_education.csv')\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT \n",
    "            LOCATION AS Country,\n",
    "            TIME AS Year,\n",
    "            Value AS \"Public Spending on Education (%)\"\n",
    "        FROM public_spending_df\n",
    "        WHERE TIME IN (2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020);\n",
    "        \"\"\"\n",
    "public_spending_df = duckdb.sql(query).df()\n",
    "public_spending_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d7073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_spending_df.to_csv('clean_public_education_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9167918",
   "metadata": {},
   "source": [
    "The two dataframes (combined_df and public_spending_df) are combined below using a Full Join, so that we will have a cohesive data frame showing enrollment rates, gdp, and total population, and public spending as a percentage of gdp of each country from 2013-2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e01151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM combined_df\n",
    "        FULL JOIN public_spending_df\n",
    "        ON combined_df.Country = public_spending_df.Country\n",
    "        AND combined_df.Year = public_spending_df.Year;\n",
    "        \"\"\"\n",
    "\n",
    "combined_df = duckdb.sql(query).df()\n",
    "combined_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c09742c",
   "metadata": {},
   "source": [
    "In the table, above there are a lot of missing values. Some countries might not have enrollment rates for either early childhood education or higher education or gdp values, or etc. and because of this a lot of Column values for Country, and Year are filled with Nan. To fix this, we have to make all the values in the Country and Country_2 column the same, and Year and Year_2 values the same. After doing this, we need to drop the Country_2 and Year_2 columns, because they are redundant and change all the float values in Year to be integers,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da1ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in Country with values from Country_2\n",
    "combined_df['Country'] = combined_df['Country'].fillna(combined_df['Country_2'])\n",
    "\n",
    "# Fill missing values in Country_2 with values from Country\n",
    "combined_df['Country_2'] = combined_df['Country_2'].fillna(combined_df['Country'])\n",
    "\n",
    "# Fill missing values in Year with values from Year_2\n",
    "combined_df['Year'] = combined_df['Year'].fillna(combined_df['Year_2'])\n",
    "\n",
    "# Fill missing values in Year_2 with values from Year\n",
    "combined_df['Year_2'] = combined_df['Year_2'].fillna(combined_df['Year'])\n",
    "\n",
    "#dropping Country_2 and Year_2 columns\n",
    "combined_df = combined_df.drop(columns=['Country_2', 'Year_2'])\n",
    "\n",
    "#making the values in the Year column integers\n",
    "combined_df['Year'] = combined_df['Year'].astype(int)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42012e7f",
   "metadata": {},
   "source": [
    "## Private Spending on Education:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c96521c",
   "metadata": {},
   "source": [
    "https://data.oecd.org/eduresource/private-spending-on-education.htm#indicator-chart\n",
    "\n",
    "This data shows private spending on education as a percentage of GDP for tertiary education. Private spending on education refers to expenditure funded by private resources which are households and other private entities. It includes all direct expenditure on education institions, and net of public subsidies.\n",
    "\n",
    "The original data set has 8 different columns: Location, Indicator, Subject, Measure, Frequency, Time, Value, Flag Codes). The Location specifies the country. The indicator specifies what is being measured (private spending on education). This column is also not necessary because there is only one value being measured in this specific data set, it is redundant. The Measure column just specifies how the data was measured, in this case it is the public spending as a percentage of gdp. Since the Measure is the same for all the rows, this column isn't necessary. The frequency column is similar to the Measure column and is also not necessary for this case. The Time column indicates what year each gdp value is from from, ranges from years 2000 to 2020. The Value column displays the percentage of gdp that is used for public education. And the last column, Flag Codes, is used for indicating something wrong for each row, in this case, because the whole column does not contain any values, this column is not necessary.\n",
    "\n",
    "From the original data set, we removed the Indicator, Subject, Measure, Frequency, and Flag Codes columns. We also renamed the \"Location\" column as \"Country\" and the \"Time\" column as \"Year\" in order to be consistent with the enrollment_rates_df. We also renamed the \"Value\" column as \"Private Spending on Education (%)\" in order to specify the value of it, which is needed when we combine all the data sets.\n",
    "\n",
    "We also need to limit Years to be in between 2013 to 2020 in order to be consistent with the previous data sets and limit the amount of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77238302",
   "metadata": {},
   "outputs": [],
   "source": [
    "private_spending_df = pd.read_csv('private_spending_on_education.csv')\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT \n",
    "            LOCATION AS Country,\n",
    "            TIME AS Year,\n",
    "            Value AS \"Private Spending on Education (%)\"\n",
    "        FROM private_spending_df\n",
    "        WHERE TIME IN (2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020);\n",
    "        \"\"\"\n",
    "private_spending_df = duckdb.sql(query).df()\n",
    "private_spending_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "private_spending_df.to_csv('clean_private_education_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43382a1",
   "metadata": {},
   "source": [
    "The two dataframes (combined_df and private_spending_df) are combined below using a Full Join, so that we will have a cohesive data frame showing enrollment rates, gdp, and total population, and public spending as a percentage of GDP, and private spending as a percentage of GDP of each country from 2013-2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM combined_df\n",
    "        FULL JOIN private_spending_df\n",
    "        ON combined_df.Country = private_spending_df.Country\n",
    "        AND combined_df.Year = private_spending_df.Year;\n",
    "        \"\"\"\n",
    "\n",
    "combined_df = duckdb.sql(query).df()\n",
    "combined_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c31cd6",
   "metadata": {},
   "source": [
    "In the table, above there are a lot of missing values. Some countries might not have enrollment rates for either early childhood education or higher education or gdp values, or etc. and because of this a lot of Column values for Country, and Year are filled with Nan. To fix this, we have to make all the values in the Country and Country_2 column the same, and Year and Year_2 values the same. After doing this, we need to drop the Country_2 and Year_2 columns, because they are redundant and change all the float values in Year to be integers,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f267447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in Country with values from Country_2\n",
    "combined_df['Country'] = combined_df['Country'].fillna(combined_df['Country_2'])\n",
    "\n",
    "# Fill missing values in Country_2 with values from Country\n",
    "combined_df['Country_2'] = combined_df['Country_2'].fillna(combined_df['Country'])\n",
    "\n",
    "# Fill missing values in Year with values from Year_2\n",
    "combined_df['Year'] = combined_df['Year'].fillna(combined_df['Year_2'])\n",
    "\n",
    "# Fill missing values in Year_2 with values from Year\n",
    "combined_df['Year_2'] = combined_df['Year_2'].fillna(combined_df['Year'])\n",
    "\n",
    "#dropping Country_2 and Year_2 columns\n",
    "combined_df = combined_df.drop(columns=['Country_2', 'Year_2'])\n",
    "\n",
    "#making the values in the Year column integers\n",
    "combined_df['Year'] = combined_df['Year'].astype(int)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999cf5a",
   "metadata": {},
   "source": [
    "## Household Income per Capita:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20497373",
   "metadata": {},
   "source": [
    "https://data.oecd.org/hha/household-disposable-income.htm#indicator-chart\n",
    "\n",
    "This data set shows the gross household disposable income per capita in 37 OECD countries. Household disposable income is available to households such as wages and salaries, income from self-employment and unincorporated enterprices, income from pensions and other social benefits, and income from financial investments. Gross means that depreciation costs are not subtracted. For gross household disposable income per capita, growth rates (percentage change from previous period) are presented; these are ‘real’ growth rates adjusted to remove the effects of price changes. Information is also presented for gross household disposable income including social transfers, such as health or education provided for free or at reduced prices by governments and not-for-profit organisations. \n",
    "\n",
    "The original data set has 8 different columns: Location, Indicator, Subject, Measure, Frequency, Time, Value, Flag Codes). The Location specifies the country. The indicator specifies what is being measured (household disposable income). This column is also not necessary because there is only one value being measured in this specific data set, it is redundant. The Measure column just specifies how the data was measured, in this case it is the household income per capita. Since the Measure is the same for all the rows, this column isn't necessary. The frequency column is similar to the Measure column and is also not necessary for this case. The Time column indicates what year each gdp value is from from, ranges from years 1970 to 2020. The Value column displays the percentage of gdp that is used for public education. And the last column, Flag Codes, is used for indicating something wrong for each row, in this case, because the whole column does not contain any values, this column is not necessary.\n",
    "\n",
    "From the original data set, we removed the Indicator, Subject, Measure, Frequency, and Flag Codes columns. We also renamed the \"Location\" column as \"Country\" and the \"Time\" column as \"Year\" in order to be consistent with the enrollment_rates_df. We also renamed the \"Value\" column as \"Household Income per Capita\" in order to specify the value of it, which is needed when we combine all the data sets.\n",
    "\n",
    "We also need to limit Years to be in between 2013 to 2020 in order to be consistent with the previous data sets and limit the amount of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8979fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "household_income_df = pd.read_csv('household_income.csv')\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT \n",
    "            LOCATION AS Country,\n",
    "            TIME AS Year,\n",
    "            Value AS \"Household Income per Capita\"\n",
    "        FROM household_income_df\n",
    "        WHERE TIME IN (2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020);\n",
    "        \"\"\"\n",
    "household_income_df = duckdb.sql(query).df()\n",
    "household_income_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8081534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "household_income_df.to_csv('clean_household_income_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ba6f88",
   "metadata": {},
   "source": [
    "The two dataframes (combined_df and household_income_df) are combined below using a Full Join, so that we will have a cohesive data frame showing enrollment rates, gdp, and total population, public spending as a percentage of GDP, private spending as a percentage of GDP, and household income per capita of each country from 2013-2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a6582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM combined_df\n",
    "        FULL JOIN household_income_df\n",
    "        ON combined_df.Country = household_income_df.Country\n",
    "        AND combined_df.Year = household_income_df.Year;\n",
    "        \"\"\"\n",
    "\n",
    "combined_df = duckdb.sql(query).df()\n",
    "combined_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670591e1",
   "metadata": {},
   "source": [
    "In the table, above there are a lot of missing values. Some countries might not have enrollment rates for either early childhood education or higher education or gdp values, or etc. and because of this a lot of Column values for Country, and Year are filled with Nan. To fix this, we have to make all the values in the Country and Country_2 column the same, and Year and Year_2 values the same. After doing this, we need to drop the Country_2 and Year_2 columns, because they are redundant and change all the float values in Year to be integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667b97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in Country with values from Country_2\n",
    "combined_df['Country'] = combined_df['Country'].fillna(combined_df['Country_2'])\n",
    "\n",
    "# Fill missing values in Country_2 with values from Country\n",
    "combined_df['Country_2'] = combined_df['Country_2'].fillna(combined_df['Country'])\n",
    "\n",
    "# Fill missing values in Year with values from Year_2\n",
    "combined_df['Year'] = combined_df['Year'].fillna(combined_df['Year_2'])\n",
    "\n",
    "# Fill missing values in Year_2 with values from Year\n",
    "combined_df['Year_2'] = combined_df['Year_2'].fillna(combined_df['Year'])\n",
    "\n",
    "#dropping Country_2 and Year_2 columns\n",
    "combined_df = combined_df.drop(columns=['Country_2', 'Year_2'])\n",
    "\n",
    "#making the values in the Year column integers\n",
    "combined_df['Year'] = combined_df['Year'].astype(int)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640911a1",
   "metadata": {},
   "source": [
    "## Education Spending:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93ac8e7",
   "metadata": {},
   "source": [
    "https://data.oecd.org/eduresource/education-spending.htm#indicator-chart\n",
    "\n",
    "This data set shows the average amount of education spending that covers expenditure on schools, universities and other public and private educational institutions in 37 OECD countries. Spending includes instruction and ancillary services for students and families provided through educational institutions. Education spending is shown in USD per student.\n",
    "\n",
    "The original data set has 8 different columns: Location, Indicator, Subject, Measure, Frequency, Time, Value, Flag Codes). The Location specifies the country. The indicator specifies what is being measured (education spending in dollars). This column is also not necessary because there is only one value being measured in this specific data set, it is redundant. The Measure column just specifies how the data was measured, in this case it is the USD per student. Since the Measure is the same for all the rows, this column isn't necessary. The frequency column is similar to the Measure column and is also not necessary for this case. The Time column indicates what year each gdp value is from from, ranges from years 1995 to 2020. The Value column displays the percentage of gdp that is used for public education. And the last column, Flag Codes, is used for indicating something wrong for each row, in this case, because the whole column does not contain any values, this column is not necessary.\n",
    "\n",
    "From the original data set, we removed the Indicator, Subject, Measure, Frequency, and Flag Codes columns. We also renamed the \"Location\" column as \"Country\" and the \"Time\" column as \"Year\" in order to be consistent with the enrollment_rates_df. We also renamed the \"Value\" column as \"Average Spending on Higher Education (USD/student)\" in order to specify the value of it, which is needed when we combine all the data sets.\n",
    "\n",
    "We also need to limit Years to be in between 2013 to 2020 in order to be consistent with the previous data sets and limit the amount of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc462e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_spending_df = pd.read_csv('educaion_spending.csv')\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT \n",
    "            LOCATION AS Country,\n",
    "            TIME AS Year,\n",
    "            Value AS \"Average Spending on Higher Education (USD/student)\"\n",
    "        FROM average_spending_df\n",
    "        WHERE TIME IN (2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020);\n",
    "        \"\"\"\n",
    "average_spending_df = duckdb.sql(query).df()\n",
    "average_spending_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cbbc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_spending_df.to_csv('clean_average_spending_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a100c94",
   "metadata": {},
   "source": [
    "The two dataframes (combined_df and average_spending_df) are combined below using a Full Join, so that we will have a cohesive data frame showing enrollment rates, gdp, and total population, public spending as a percentage of GDP, private spending as a percentage of GDP, household income per capita, and average spending for higher education per student of each country from 2013-2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68dad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM combined_df\n",
    "        FULL JOIN average_spending_df\n",
    "        ON combined_df.Country = average_spending_df.Country\n",
    "        AND combined_df.Year = average_spending_df.Year;\n",
    "        \"\"\"\n",
    "\n",
    "combined_df = duckdb.sql(query).df()\n",
    "combined_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d08db8c",
   "metadata": {},
   "source": [
    "In the table, above there are a lot of missing values. Some countries might not have enrollment rates for either early childhood education or higher education or gdp values, or etc. and because of this a lot of Column values for Country, and Year are filled with Nan. To fix this, we have to make all the values in the Country and Country_2 column the same, and Year and Year_2 values the same. After doing this, we need to drop the Country_2 and Year_2 columns, because they are redundant and change all the float values in Year to be integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeecaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in Country with values from Country_2\n",
    "combined_df['Country'] = combined_df['Country'].fillna(combined_df['Country_2'])\n",
    "\n",
    "# Fill missing values in Country_2 with values from Country\n",
    "combined_df['Country_2'] = combined_df['Country_2'].fillna(combined_df['Country'])\n",
    "\n",
    "# Fill missing values in Year with values from Year_2\n",
    "combined_df['Year'] = combined_df['Year'].fillna(combined_df['Year_2'])\n",
    "\n",
    "# Fill missing values in Year_2 with values from Year\n",
    "combined_df['Year_2'] = combined_df['Year_2'].fillna(combined_df['Year'])\n",
    "\n",
    "#dropping Country_2 and Year_2 columns\n",
    "combined_df = combined_df.drop(columns=['Country_2', 'Year_2'])\n",
    "\n",
    "#making the values in the Year column integers\n",
    "combined_df['Year'] = combined_df['Year'].astype(int)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33305ca",
   "metadata": {},
   "source": [
    "## Number of Universities:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34389d4",
   "metadata": {},
   "source": [
    "We weren't able to find a data set that directly listed the amount of universities in each OECD country. Because of this, we had to make a data set on Excel and convert to a csv later.\n",
    "\n",
    "All the information from the data set was found from this website: https://www.webometrics.info/en/distribution_by_country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_universities_df = pd.read_csv('number_of_universities.csv')\n",
    "num_universities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acebf249",
   "metadata": {},
   "source": [
    "The two dataframes (combined_df and num_universities_df) are combined below using a Left Join, so that we will have a cohesive data frame showing enrollment rates, gdp, and total population, public spending as a percentage of GDP, private spending as a percentage of GDP, household income per capita, average spending for higher education per student, and number of universities for each country from 2013-2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(combined_df, num_universities_df, on='Country', how='left')\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d7d820",
   "metadata": {},
   "source": [
    "## Population who have completed Tertiary Education:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc7599b",
   "metadata": {},
   "source": [
    "https://data.oecd.org/eduatt/population-with-tertiary-education.htm\n",
    "\n",
    "This data set shows the population with tertiary education. Tertiary education includes bachelor's and higher levels of education. The measure is percentage of same age population.\n",
    "\n",
    "The original data set has 8 different columns: Location, Indicator, Subject, Measure, Frequency, Time, Value, Flag Codes). The Location specifies the country. The indicator specifies what is being measured (percent of population that have completed their tertiary education). This column is also not necessary because there is only one value being measured in this specific data set, it is redundant. The Measure column just specifies how the data was measured. Since the Measure is the same for all the rows, this column isn't necessary. The frequency column is similar to the Measure column and is also not necessary for this case. The Time column indicates what year the data is from, ranges from years 1989 to 2020. The Value column displays the percentage of the population with tertiary education. And the last column, Flag Codes, is used for indicating something wrong for each row, in this case, because the whole column does not contain any values, this column is not necessary.\n",
    "\n",
    "From the original data set, we removed the Indicator, Subject, Measure, Frequency, and Flag Codes columns. We also renamed the \"Location\" column as \"Country\" and the \"Time\" column as \"Year\" in order to be consistent with the enrollment_rates_df. We also renamed the \"Value\" column as \"Population with Tertiary Education(%)\" in order to specify the value of it, which is needed when we combine all the data sets.\n",
    "\n",
    "We also need to limit Years to be in between 2013 to 2020 in order to be consistent with the previous data sets and limit the amount of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b02de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_tertiary_edu_df = pd.read_csv('completed_tertiary_edu.csv')\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT \n",
    "            LOCATION AS Country,\n",
    "            TIME AS Year,\n",
    "            Value AS \"Population with Tertiary Education (%)\"\n",
    "        FROM completed_tertiary_edu_df\n",
    "        WHERE TIME IN (2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020);\n",
    "        \"\"\"\n",
    "completed_tertiary_edu_df = duckdb.sql(query).df()\n",
    "completed_tertiary_edu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b578de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_tertiary_edu_df.to_csv('clean_completed_tertiary_edu_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa9c804",
   "metadata": {},
   "source": [
    "The two dataframes (combined_df and completed_tertiary_edu_df) are combined below using a Full Join, so that we will have a cohesive data frame showing enrollment rates, gdp, and total population, public spending as a percentage of GDP, private spending as a percentage of GDP, household income per capita, and average spending for higher education per student, number of universities, and population with tertiary education of each country from 2013-2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e82b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM combined_df\n",
    "        FULL JOIN completed_tertiary_edu_df\n",
    "        ON combined_df.Country = completed_tertiary_edu_df.Country\n",
    "        AND combined_df.Year = completed_tertiary_edu_df.Year;\n",
    "        \"\"\"\n",
    "\n",
    "combined_df = duckdb.sql(query).df()\n",
    "combined_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aab091",
   "metadata": {},
   "source": [
    "In the table, above there are a lot of missing values. Some countries might not have enrollment rates for either early childhood education or higher education or gdp values, or etc. and because of this a lot of Column values for Country, and Year are filled with Nan. To fix this, we have to make all the values in the Country and Country_2 column the same, and Year and Year_2 values the same. After doing this, we need to drop the Country_2 and Year_2 columns, because they are redundant and change all the float values in Year to be integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d07446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in Country with values from Country_2\n",
    "combined_df['Country'] = combined_df['Country'].fillna(combined_df['Country_2'])\n",
    "\n",
    "# Fill missing values in Country_2 with values from Country\n",
    "combined_df['Country_2'] = combined_df['Country_2'].fillna(combined_df['Country'])\n",
    "\n",
    "# Fill missing values in Year with values from Year_2\n",
    "combined_df['Year'] = combined_df['Year'].fillna(combined_df['Year_2'])\n",
    "\n",
    "# Fill missing values in Year_2 with values from Year\n",
    "combined_df['Year_2'] = combined_df['Year_2'].fillna(combined_df['Year'])\n",
    "\n",
    "#dropping Country_2 and Year_2 columns\n",
    "combined_df = combined_df.drop(columns=['Country_2', 'Year_2'])\n",
    "\n",
    "#making the values in the Year column integers\n",
    "combined_df['Year'] = combined_df['Year'].astype(int)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad37b240",
   "metadata": {},
   "source": [
    "Since some of the rows above in the combined data frame, have values for OECD, which represents the averages across all the countries, we are going to drop those rows, since not all the data frames that we joined in this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a273c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[combined_df['Country'] != 'OECD']\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc3f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('combined_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
